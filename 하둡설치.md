
# 하둡 설치 사전작업
sudo apt-get install ssh
sudo apt-get install pdsh

.bashrc 편집
export PDSH_RCMD_TYPE=ssh


ssh-keygen -t rsa -P ""
cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys


# 하둡 설치
hadoop/etc/hadoop/hadoop-env.sh 편집
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64

hadoop/etc/hadoop/core-site.xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/home/ubuntu/hdata</value>
    </property>
</configuration>

hadoop/etc/hadoop/hdfs-site.xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
    <property>
        <name>dfs.name.dir</name>
        <value>file:///home/ubuntu/hadoop/hdfs/namenode</value>
    </property>
    <property>
        <name>dfs.data.dir</name>
        <value>file:///home/ubuntu/hadoop/hdfs/datanode</value>
    </property>
</configuration>


hadoop/etc/hadoop/mapred-site.xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=/home/ubuntu/hadoop</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=/home/ubuntu/hadoop</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=/home/ubuntu/hadoop</value>
    </property>
</configuration>

hadoop/etc/hadoop/yarn-site.xml
<configuration>
<!-- Site specific YARN configuration properties -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services.mapreduce.shuffle.classs</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
</configuration>

.bashrc 편집

export PDSH_RCMD_TYPE=ssh
export HADOOP_HOME="/home/ubuntu/hadoop"
export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin
export HADOOP_MAPRED_HOME=${HADOOP_HOME}
export HADOOP_COMMON_HOME=${HADOOP_HOME}
export HADOOP_HDFS_HOME=${HADOOP_HOME}
export YARN_HOME=${HADOOP_HOME}

# 모듈 기동 및 종료
-- Format NameNode in HDFS
hadoop/bin/hdfs namenode -format
 -- HDFS 실행
hadoop/sbin/start-dfs.sh
start-yarn.sh

http://3.34.131.239:9870/ 접속
http://3.34.131.239:8042/
http://3.34.131.239:9864/datanode.html

stop-yarn.sh
sbin/stop-dfs.sh

# 명령어 mkdir, ls, touchz
hadoop fs -mkdir /user
hadoop fs -ls /

hdfs dfs -mkdir /hdfs-user
hdfs dfs -ls /

ubuntu@ip-100-51-0-38:~/hadoop$ hdfs dfs -ls /hdfs-user
ubuntu@ip-100-51-0-38:~/hadoop$ hdfs dfs -touchz /hdfs-user/test.txt

ubuntu@ip-100-51-0-38:~/hadoop$ hadoop fs -touchz /user/hadoop-test.txt
ubuntu@ip-100-51-0-38:~/hadoop$ hadoop fs -ls /user

# 명령어 put, copyFromLocal
ubuntu@ip-100-51-0-38:~/hadoop$ hadoop fs -put ./logs/*.log /user/etc
ubuntu@ip-100-51-0-38:~/hadoop$ hadoop fs -ls /user
ubuntu@ip-100-51-0-38:~/hadoop$ hadoop fs -ls /user/etc

ubuntu@ip-100-51-0-38:~/hadoop$ hdfs dfs -copyFromLocal /etc/apt/ /user/etc/apt
ubuntu@ip-100-51-0-38:~/hadoop$ hdfs dfs -ls /user/etc/apt

# 명령어 get, copyToLocal
hadoop fs -get /user/etc/apt/sources.list /tmp
ubuntu@ip-100-51-0-38:~$ hdfs dfs -copyToLocal /user/hadoop-test.txt /tmp

# 명령어 cat, mv, cp, rm
hdfs dfs -cat /user/etc/hadoop-ubuntu-datanode-ip-100-51-0-38.log
hdfs dfs -mv /user/etc/apt /user/etc/apt2
hdfs dfs -cp /user/etc/apt2 /user/etc/apt3

ubuntu@ip-100-51-0-38:~/hadoop$ hdfs dfs -rm /user/etc/apt3/sources.list
Deleted /user/etc/apt3/sources.list
ubuntu@ip-100-51-0-38:~/hadoop$ hdfs dfs -rm -r /user/etc/apt3
Deleted /user/etc/apt3


# 명령어 chmod, chown
ubuntu@ip-100-51-0-38:~/hadoop$ hdfs dfs -chmod -R 755 /user/etc/
ubuntu@ip-100-51-0-38:~/hadoop$ hdfs dfs -ls /user/etc

ubuntu@ip-100-51-0-38:~/hadoop$ hdfs dfs -chown root /user/etc/apt2

# User Command
ubuntu@ip-100-51-0-38:~/hadoop$ hadoop checknative -a
ubuntu@ip-100-51-0-38:~/hadoop$ hadoop classpath
ubuntu@ip-100-51-0-38:~/hadoop$ hadoop conftest
ubuntu@ip-100-51-0-38:~/hadoop$ hadoop kdiag
ubuntu@ip-100-51-0-38:~/hadoop$ hadoop envvars
ubuntu@ip-100-51-0-38:~/hadoop$ hadoop version



ubuntu@ip-100-51-0-38:~/hadoop/lib/native$ hadoop credential list -provider jceks://file/tmp/test.jceks
Listing aliases for CredentialProvider: jceks://file/tmp/test.jceks

ubuntu@ip-100-51-0-38:~/hadoop/share/hadoop/mapreduce$ hadoop jar ./hadoop-mapreduce-examples-3.3.1.jar pi 16 1000



# 샘플예제 실행 NOTICE.txt 단어 분석
ubuntu@ip-100-51-0-38:~/hadoop/share/hadoop/mapreduce$ hdfs dfs -mkdir /user/ubuntu/input
ubuntu@ip-100-51-0-38:~/hadoop/share/hadoop/mapreduce$ hdfs dfs -ls /user/ubuntu/input
ubuntu@ip-100-51-0-38:~/hadoop/share/hadoop/mapreduce$ cd
ubuntu@ip-100-51-0-38:~$ cd hadoop
ubuntu@ip-100-51-0-38:~/hadoop$ hdfs dfs -put NOTICE.txt /user/ubuntu/input
ubuntu@ip-100-51-0-38:~/hadoop$ hdfs dfs -ls -R /user/ubuntu/input
-rw-r--r--   1 ubuntu supergroup       1541 2021-10-03 02:34 /user/ubuntu/input/NOTICE.txt
ubuntu@ip-100-51-0-38:~/hadoop$
ubuntu@ip-100-51-0-38:~/hadoop$ cd share/hadoop/mapreduce/
ubuntu@ip-100-51-0-38:~/hadoop/share/hadoop/mapreduce$ hadoop jar ./hadoop-mapreduce-examples-3.2.2.jar wordcount input output

ubuntu@ip-100-51-0-38:~/hadoop/share/hadoop/mapreduce$ hdfs dfs -ls /user/ubuntu/output
Found 2 items
-rw-r--r--   1 ubuntu supergroup          0 2021-10-03 02:35 /user/ubuntu/output/_SUCCESS
-rw-r--r--   1 ubuntu supergroup       1402 2021-10-03 02:35 /user/ubuntu/output/part-r-00000

-- 단어별 빈도수 확인
ubuntu@ip-100-51-0-38:~/hadoop/share/hadoop/mapreduce$ hdfs dfs -cat /user/ubuntu/output/part-r-00000


# eBook 분석(https://gutenberg.org/)
ubuntu@ip-100-51-0-38:~/hadoop/mapreduce/input$ hdfs dfs -mkdir /user/mapreduce
ubuntu@ip-100-51-0-38:~/hadoop/mapreduce/input$ hdfs dfs -ls /user/mapreduce
ubuntu@ip-100-51-0-38:~/hadoop/mapreduce/input$ hdfs dfs -copyFromLocal ./*.txt /user/mapreduce
ubuntu@ip-100-51-0-38:~/hadoop/mapreduce/input$ hdfs dfs -ls /user/mapreduce
Found 2 items
-rw-r--r--   1 ubuntu supergroup      33520 2021-10-03 03:28 /user/mapreduce/book.txt
-rw-r--r--   1 ubuntu supergroup     495572 2021-10-03 03:28 /user/mapreduce/book2.txt

ubuntu@ip-100-51-0-38:~/hadoop/mapreduce$ hadoop jar ~/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.3.1.jar \
> -file ~/hadoop/mapreduce/mapper.py -mapper ~/hadoop/mapreduce/mapper.py \
> -file ~/hadoop/mapreduce/reducer.py -reducer ~/hadoop/mapreduce/reducer.py \
> -input /user/mapreduce/* -output /user/mapreduce/output-ebook

ubuntu@ip-100-51-0-38:~/hadoop/mapreduce$ hdfs dfs -cat /user/mapreduce/output-ebook/part-00000

